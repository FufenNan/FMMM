{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "import torch\n",
    "import numpy as np\n",
    "from dataset import dataset_VQ, dataset_TM_eval\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from os.path import join as pjoin\n",
    "from torch.distributions import Categorical\n",
    "import json\n",
    "from exit.utils import animate3d, t2m_bone\n",
    "import clip\n",
    "from utils.motion_process import recover_from_ric\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"4\"\n",
    "import options.option_transformer as option_trans\n",
    "import models.vqvae as vqvae\n",
    "import utils.utils_model as utils_model\n",
    "import utils.eval_trans as eval_trans\n",
    "from dataset import dataset_TM_train\n",
    "from dataset import dataset_TM_eval\n",
    "from dataset import dataset_tokenize\n",
    "import models.t2m_trans_multi as trans\n",
    "from options.get_eval_option import get_opt\n",
    "from models.evaluator_wrapper import EvaluatorModelWrapper\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "from exit.utils import get_model, visualize_2motions\n",
    "from tqdm import tqdm\n",
    "from exit.utils import get_model, visualize_2motions, generate_src_mask, init_save_folder, uniform, cosine_schedule\n",
    "from einops import rearrange, repeat\n",
    "import torch.nn.functional as F\n",
    "from exit.utils import base_dir\n",
    "from models.vqvae_multi import VQVAE_MULTI_V2\n",
    "from models.vqvae_general import HumanVQVAE_GENERAL,VQVAE_decode_only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Temp:\n",
    "    def __init__(self, extra_args=None):\n",
    "        print('mock:: opt')\n",
    "        if extra_args is not None:\n",
    "            for i in extra_args:\n",
    "                self.__dict__[i] = extra_args[i]\n",
    "args = Temp()\n",
    "\n",
    "args.dataname = args.dataset_name = 't2m'\n",
    "args.nb_code = 256\n",
    "args.code_dim = 32\n",
    "args.output_emb_width = 512\n",
    "args.down_t = 2\n",
    "args.stride_t = 2\n",
    "args.width = 512\n",
    "args.depth = 3\n",
    "args.dilation_growth_rate = 3\n",
    "args.quantizer = 'ema_reset'\n",
    "args.mu = 0.99\n",
    "args.clip_dim = 512\n",
    "\n",
    "\n",
    "args.embed_dim_gpt = 1280\n",
    "args.block_size = 51\n",
    "args.num_layers = 9\n",
    "args.n_head_gpt = 16\n",
    "args.drop_out_rate = 0.1\n",
    "args.ff_rate = 4\n",
    "\n",
    "args.total_iter = 10\n",
    "args.batch_size = 1\n",
    "args.vq_name ='2024-08-12-23-14-09_vq5_multi'\n",
    "args.resume_trans='/home/haoyum3/MMM/output/t2m/2024-08-14-12-01-17_trans_multi_1/net_last.pth'\n",
    "args.resume_pth='/home/haoyum3/MMM/output/vq/2024-08-12-23-14-09_vq5_multi/net_last.pth'\n",
    "args.num_local_layer =2\n",
    "args.pkeep = 0.5\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.word_vectorizer import WordVectorizer\n",
    "w_vectorizer = WordVectorizer('./glove', 'our_vab')\n",
    "val_loader = dataset_TM_eval.DATALoader(args.dataname, False, 32, w_vectorizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "args.teacher_pth=\"/home/haoyum3/MMM/output/vq/2024-08-16-23-15-13_multi_vq_256_32_5/net_last.pth\"\n",
    "args.vq_act='relu'\n",
    "args.vq_norm=None\n",
    "if args.teacher_pth:\n",
    "    teacher_net= VQVAE_MULTI_V2(args, ## use args to define different parameters in different quantizers\n",
    "                            args.nb_code,#8192\n",
    "                            args.code_dim,#32\n",
    "                            args.output_emb_width,#512\n",
    "                            args.down_t,#2\n",
    "                            args.stride_t,#2\n",
    "                            args.width,#512\n",
    "                            args.depth,#3\n",
    "                            args.dilation_growth_rate,#3\n",
    "                            args.vq_act,#'relu'\n",
    "                            args.vq_norm,#None\n",
    "                            {'mean': torch.from_numpy(val_loader.dataset.mean).cuda().float(), \n",
    "                            'std': torch.from_numpy(val_loader.dataset.std).cuda().float()},\n",
    "                            True)\n",
    "    teacher_ckpt=torch.load(args.teacher_pth, map_location='cpu')\n",
    "    teacher_net.load_state_dict(teacher_ckpt['net'], strict=True)\n",
    "    teacher_net.cuda()\n",
    "    teacher_net.eval()\n",
    "net= VQVAE_decode_only(args, ## use args to define different parameters in different quantizers\n",
    "                        teacher_net,\n",
    "                        args.nb_code,#8192\n",
    "                        args.code_dim,#32\n",
    "                        args.output_emb_width,#512\n",
    "                        args.down_t,#2\n",
    "                        args.stride_t,#2\n",
    "                        args.width,#512\n",
    "                        args.depth,#3\n",
    "                        args.dilation_growth_rate,#3\n",
    "                        args.vq_act,#'relu'\n",
    "                        args.vq_norm,#None\n",
    "            )\n",
    "args.resume_pth='/home/haoyum3/MMM/output/vq/2024-08-19-00-17-48_vq_general_decoder/net_last.pth'\n",
    "if args.resume_pth : \n",
    "    ckpt = torch.load(args.resume_pth, map_location='cpu')\n",
    "    net.load_state_dict(ckpt['net'], strict=True)\n",
    "#net = torch.nn.DataParallel(net)\n",
    "net.eval()\n",
    "net.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "args.batch_size=1\n",
    "args.window_size=64\n",
    "train_loader = dataset_VQ.DATALoader(args.dataname,\n",
    "                                        args.batch_size,\n",
    "                                        window_size=args.window_size,\n",
    "                                        unit_length=2**args.down_t)\n",
    "\n",
    "train_loader_iter = dataset_VQ.cycle(train_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gt_motion = next(train_loader_iter)\n",
    "gt_motion = gt_motion.cuda().float() # bs, nb_joints, joints_dim, seq_len\n",
    "pose = gt_motion[0, :].detach().cpu().numpy() * val_loader.dataset.std + val_loader.dataset.mean\n",
    "pose = recover_from_ric(torch.from_numpy(pose).float(), 22).numpy()\n",
    "animate3d(pose, BONE_LINK=t2m_bone, first_total_standard=63, axis_visible=True)\n",
    "pred_motion = net(gt_motion)\n",
    "pose = pred_motion[0, :].detach().cpu().numpy() * val_loader.dataset.std + val_loader.dataset.mean\n",
    "pose = recover_from_ric(torch.from_numpy(pose).float(), 22).numpy()\n",
    "animate3d(pose, BONE_LINK=t2m_bone, first_total_standard=63, axis_visible=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gt_motion1 = gt_motion.clone()\n",
    "tokens=teacher_net(gt_motion1,type='encode')\n",
    "print(tokens.shape)\n",
    "gt_motion2 = next(train_loader_iter)\n",
    "pose = gt_motion2[0, :].detach().cpu().numpy() * val_loader.dataset.std + val_loader.dataset.mean\n",
    "pose = recover_from_ric(torch.from_numpy(pose).float(), 22).numpy()\n",
    "animate3d(pose, BONE_LINK=t2m_bone, first_total_standard=63, axis_visible=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gt_motion1 = gt_motion.clone()\n",
    "tokens1=teacher_net(gt_motion1,type='encode')\n",
    "print(tokens1.shape)\n",
    "gt_motion2=gt_motion2.cuda().float()\n",
    "tokens2=teacher_net(gt_motion2,type='encode')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tokens1[...,0]=tokens2[...,0]\n",
    "# tokens1[...,1]=tokens2[...,1]\n",
    "tokens1[...,2]=tokens2[...,2]\n",
    "tokens1[...,3]=tokens2[...,3]\n",
    "# tokens1[...,4]=tokens2[...,4]\n",
    "emb=teacher_net(tokens1,type='decode')\n",
    "print(emb.shape)\n",
    "pose = emb[0, :].detach().cpu().numpy() * val_loader.dataset.std + val_loader.dataset.mean\n",
    "pose = recover_from_ric(torch.from_numpy(pose).float(), 22).numpy()\n",
    "animate3d(pose, BONE_LINK=t2m_bone, first_total_standard=63, axis_visible=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# token_emb=teacher_net(emb,type='token_emb')\n",
    "# print(token_emb.shape)\n",
    "pred_motion = net(emb)\n",
    "pose = pred_motion[0, :].detach().cpu().numpy() * val_loader.dataset.std + val_loader.dataset.mean\n",
    "pose = recover_from_ric(torch.from_numpy(pose).float(), 22).numpy()\n",
    "animate3d(pose, BONE_LINK=t2m_bone, first_total_standard=63, axis_visible=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from einops import rearrange, repeat\n",
    "batch_size = 10\n",
    "max_len = 50\n",
    "m_tokens_len = torch.randint(1,50,(batch_size,))\n",
    "rand_mask_probs = torch.zeros(batch_size).float().uniform_(0.5, 1)\n",
    "# rand_mask_probs = cosine_schedule(rand_mask_probs)\n",
    "num_token_masked = (m_tokens_len * rand_mask_probs).round().clamp(min = 1)\n",
    "batch_randperm = torch.rand((batch_size, max_len))\n",
    "batch_randperm = batch_randperm.argsort(dim=-1)\n",
    "mask_token = batch_randperm < rearrange(num_token_masked, 'b -> b 1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "batch_size = 10\n",
    "max_len = 50\n",
    "m_tokens_len = torch.randint(1,50,(batch_size,))\n",
    "rand_mask_probs = torch.zeros(batch_size).float().uniform_(0.5, 1)\n",
    "# rand_mask_probs = cosine_schedule(rand_mask_probs)\n",
    "num_token_masked = (m_tokens_len * rand_mask_probs).round().clamp(min = 1)\n",
    "batch_randperm = torch.rand((batch_size, max_len))\n",
    "batch_randperm = batch_randperm.argsort(dim=-1)\n",
    "mask_token = batch_randperm < rearrange(num_token_masked, 'b -> b 1')\n",
    "mask_token = mask_token.unsqueeze(-1).repeat(1,1,5)\n",
    "mask_token= mask_token.permute(0,2,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid character '，' (U+FF0C) (2618191362.py, line 7)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  Cell \u001b[0;32mIn[5], line 7\u001b[0;36m\u001b[0m\n\u001b[0;31m    index = torch.tensor([[0，1], [1, 0], [0, 0]])\u001b[0m\n\u001b[0m                            ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid character '，' (U+FF0C)\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "# 创建一个示例张量\n",
    "x = torch.tensor([[1, 2], [3, 4], [5, 6]])\n",
    "\n",
    "# 指定索引张量\n",
    "index = torch.tensor([[0,1], [1, 0], [0, 0]])\n",
    "\n",
    "# 使用 gather 函数\n",
    "result = torch.gather(x, 1, index)\n",
    "\n",
    "print(result)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "MMM",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
